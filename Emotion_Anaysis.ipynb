{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion_Anaysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN1sqLpV1bqR",
        "colab_type": "code",
        "outputId": "81341a62-f37d-4f3a-df18-77cb58fd8dd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbrkxkK1LvY0",
        "colab_type": "code",
        "outputId": "023e8d3e-4336-4388-9f9f-0887f8ecb6bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6562
        }
      },
      "source": [
        "import sys, os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils\n",
        "# pd.set_option('display.max_rows', 500)\n",
        "# pd.set_option('display.max_columns', 500)\n",
        "# pd.set_option('display.width', 1000)\n",
        "\n",
        "df=pd.read_csv('gdrive/My Drive/fer2013.csv')\n",
        "\n",
        "# print(df.info())\n",
        "# print(df[\"Usage\"].value_counts())\n",
        "\n",
        "# print(df.head())\n",
        "X_train,train_y,X_test,test_y=[],[],[],[]\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    val=row['pixels'].split(\" \")\n",
        "    try:\n",
        "        if 'Training' in row['Usage']:\n",
        "           X_train.append(np.array(val,'float32'))\n",
        "           train_y.append(row['emotion'])\n",
        "        elif 'PublicTest' in row['Usage']:\n",
        "           X_test.append(np.array(val,'float32'))\n",
        "           test_y.append(row['emotion'])\n",
        "    except:\n",
        "        print(f\"error occured at index :{index} and row:{row}\")\n",
        "\n",
        "\n",
        "num_features = 64\n",
        "num_labels = 7\n",
        "batch_size = 64\n",
        "epochs = 200\n",
        "width, height = 48, 48\n",
        "\n",
        "\n",
        "X_train = np.array(X_train,'float32')\n",
        "train_y = np.array(train_y,'float32')\n",
        "X_test = np.array(X_test,'float32')\n",
        "test_y = np.array(test_y,'float32')\n",
        "\n",
        "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
        "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)\n",
        "\n",
        "#cannot produce\n",
        "#normalizing data between oand 1\n",
        "X_train -= np.mean(X_train, axis=0)\n",
        "X_train /= np.std(X_train, axis=0)\n",
        "\n",
        "X_test -= np.mean(X_test, axis=0)\n",
        "X_test /= np.std(X_test, axis=0)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
        "\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n",
        "\n",
        "# print(f\"shape:{X_train.shape}\")\n",
        "##designing the cnn\n",
        "#1st convolution layer\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
        "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#2nd convolution layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#3rd convolution layer\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#fully connected neural networks\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(num_labels, activation='softmax'))\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "#Compliling the model\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Training the model\n",
        "model.fit(X_train, train_y,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, test_y),\n",
        "          shuffle=True)\n",
        "\n",
        "\n",
        "#Saving the  model to  use it later on\n",
        "fer_json = model.to_json()\n",
        "with open(\"fer.json\", \"w\") as json_file:\n",
        "    json_file.write(fer_json)\n",
        "model.save_weights(\"fer.h5\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 28709 samples, validate on 3589 samples\n",
            "Epoch 1/200\n",
            "28709/28709 [==============================] - 11s 369us/step - loss: 1.7274 - acc: 0.2937 - val_loss: 1.5473 - val_acc: 0.3862\n",
            "Epoch 2/200\n",
            "28709/28709 [==============================] - 9s 328us/step - loss: 1.5182 - acc: 0.4059 - val_loss: 1.4057 - val_acc: 0.4377\n",
            "Epoch 3/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 1.4109 - acc: 0.4553 - val_loss: 1.3337 - val_acc: 0.4806\n",
            "Epoch 4/200\n",
            "28709/28709 [==============================] - 9s 329us/step - loss: 1.3445 - acc: 0.4830 - val_loss: 1.2841 - val_acc: 0.4999\n",
            "Epoch 5/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 1.3077 - acc: 0.4946 - val_loss: 1.2569 - val_acc: 0.5121\n",
            "Epoch 6/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 1.2674 - acc: 0.5167 - val_loss: 1.2304 - val_acc: 0.5252\n",
            "Epoch 7/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 1.2401 - acc: 0.5230 - val_loss: 1.2394 - val_acc: 0.5244\n",
            "Epoch 8/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 1.2177 - acc: 0.5355 - val_loss: 1.2105 - val_acc: 0.5386\n",
            "Epoch 9/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 1.1868 - acc: 0.5462 - val_loss: 1.1963 - val_acc: 0.5400\n",
            "Epoch 10/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 1.1722 - acc: 0.5528 - val_loss: 1.1963 - val_acc: 0.5411\n",
            "Epoch 11/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 1.1479 - acc: 0.5605 - val_loss: 1.1797 - val_acc: 0.5489\n",
            "Epoch 12/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 1.1372 - acc: 0.5668 - val_loss: 1.1629 - val_acc: 0.5464\n",
            "Epoch 13/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 1.1145 - acc: 0.5729 - val_loss: 1.1523 - val_acc: 0.5603\n",
            "Epoch 14/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 1.0974 - acc: 0.5786 - val_loss: 1.1678 - val_acc: 0.5500\n",
            "Epoch 15/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 1.0796 - acc: 0.5877 - val_loss: 1.1758 - val_acc: 0.5492\n",
            "Epoch 16/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 1.0705 - acc: 0.5898 - val_loss: 1.1373 - val_acc: 0.5748\n",
            "Epoch 17/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 1.0452 - acc: 0.5995 - val_loss: 1.1369 - val_acc: 0.5782\n",
            "Epoch 18/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 1.0413 - acc: 0.6012 - val_loss: 1.1479 - val_acc: 0.5692\n",
            "Epoch 19/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 1.0221 - acc: 0.6118 - val_loss: 1.1457 - val_acc: 0.5709\n",
            "Epoch 20/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 1.0037 - acc: 0.6189 - val_loss: 1.1904 - val_acc: 0.5539\n",
            "Epoch 21/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.9915 - acc: 0.6260 - val_loss: 1.1616 - val_acc: 0.5634\n",
            "Epoch 22/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.9759 - acc: 0.6304 - val_loss: 1.1437 - val_acc: 0.5729\n",
            "Epoch 23/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.9606 - acc: 0.6351 - val_loss: 1.1516 - val_acc: 0.5759\n",
            "Epoch 24/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.9515 - acc: 0.6381 - val_loss: 1.1345 - val_acc: 0.5768\n",
            "Epoch 25/200\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.9292 - acc: 0.6441 - val_loss: 1.1738 - val_acc: 0.5662\n",
            "Epoch 26/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.9239 - acc: 0.6481 - val_loss: 1.1826 - val_acc: 0.5790\n",
            "Epoch 27/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.9038 - acc: 0.6580 - val_loss: 1.2064 - val_acc: 0.5687\n",
            "Epoch 28/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.8991 - acc: 0.6570 - val_loss: 1.1781 - val_acc: 0.5695\n",
            "Epoch 29/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.8785 - acc: 0.6683 - val_loss: 1.1882 - val_acc: 0.5840\n",
            "Epoch 30/200\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.8652 - acc: 0.6698 - val_loss: 1.2141 - val_acc: 0.5695\n",
            "Epoch 31/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.8572 - acc: 0.6771 - val_loss: 1.2313 - val_acc: 0.5651\n",
            "Epoch 32/200\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.8416 - acc: 0.6844 - val_loss: 1.2080 - val_acc: 0.5617\n",
            "Epoch 33/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.8379 - acc: 0.6876 - val_loss: 1.2147 - val_acc: 0.5704\n",
            "Epoch 34/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.8231 - acc: 0.6870 - val_loss: 1.2161 - val_acc: 0.5698\n",
            "Epoch 35/200\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.8032 - acc: 0.6972 - val_loss: 1.1971 - val_acc: 0.5848\n",
            "Epoch 36/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.8068 - acc: 0.6952 - val_loss: 1.2326 - val_acc: 0.5734\n",
            "Epoch 37/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.7877 - acc: 0.7051 - val_loss: 1.2494 - val_acc: 0.5818\n",
            "Epoch 38/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.7820 - acc: 0.7052 - val_loss: 1.2611 - val_acc: 0.5731\n",
            "Epoch 39/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.7634 - acc: 0.7130 - val_loss: 1.2440 - val_acc: 0.5726\n",
            "Epoch 40/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.7549 - acc: 0.7173 - val_loss: 1.2870 - val_acc: 0.5765\n",
            "Epoch 41/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.7390 - acc: 0.7220 - val_loss: 1.2617 - val_acc: 0.5773\n",
            "Epoch 42/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.7424 - acc: 0.7213 - val_loss: 1.2903 - val_acc: 0.5626\n",
            "Epoch 43/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.7380 - acc: 0.7229 - val_loss: 1.2547 - val_acc: 0.5692\n",
            "Epoch 44/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.7154 - acc: 0.7356 - val_loss: 1.3186 - val_acc: 0.5829\n",
            "Epoch 45/200\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.7089 - acc: 0.7347 - val_loss: 1.2719 - val_acc: 0.5762\n",
            "Epoch 46/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.6960 - acc: 0.7418 - val_loss: 1.2883 - val_acc: 0.5756\n",
            "Epoch 47/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.6930 - acc: 0.7425 - val_loss: 1.2938 - val_acc: 0.5793\n",
            "Epoch 48/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.6795 - acc: 0.7477 - val_loss: 1.3409 - val_acc: 0.5762\n",
            "Epoch 49/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.6664 - acc: 0.7528 - val_loss: 1.3276 - val_acc: 0.5651\n",
            "Epoch 50/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.6754 - acc: 0.7499 - val_loss: 1.3510 - val_acc: 0.5784\n",
            "Epoch 51/200\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.6598 - acc: 0.7547 - val_loss: 1.3616 - val_acc: 0.5720\n",
            "Epoch 52/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.6559 - acc: 0.7571 - val_loss: 1.3348 - val_acc: 0.5851\n",
            "Epoch 53/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.6407 - acc: 0.7600 - val_loss: 1.3386 - val_acc: 0.5829\n",
            "Epoch 54/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.6458 - acc: 0.7618 - val_loss: 1.3742 - val_acc: 0.5729\n",
            "Epoch 55/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.6309 - acc: 0.7666 - val_loss: 1.3392 - val_acc: 0.5723\n",
            "Epoch 56/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.6296 - acc: 0.7678 - val_loss: 1.3955 - val_acc: 0.5701\n",
            "Epoch 57/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.6087 - acc: 0.7732 - val_loss: 1.3747 - val_acc: 0.5690\n",
            "Epoch 58/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.6030 - acc: 0.7781 - val_loss: 1.4097 - val_acc: 0.5762\n",
            "Epoch 59/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.6031 - acc: 0.7796 - val_loss: 1.4175 - val_acc: 0.5723\n",
            "Epoch 60/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.5877 - acc: 0.7823 - val_loss: 1.4252 - val_acc: 0.5754\n",
            "Epoch 61/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.5887 - acc: 0.7843 - val_loss: 1.4415 - val_acc: 0.5795\n",
            "Epoch 62/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.5753 - acc: 0.7865 - val_loss: 1.3601 - val_acc: 0.5784\n",
            "Epoch 63/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.5728 - acc: 0.7901 - val_loss: 1.4199 - val_acc: 0.5815\n",
            "Epoch 64/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.5752 - acc: 0.7896 - val_loss: 1.4053 - val_acc: 0.5765\n",
            "Epoch 65/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.5518 - acc: 0.7971 - val_loss: 1.5581 - val_acc: 0.5642\n",
            "Epoch 66/200\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.5536 - acc: 0.7989 - val_loss: 1.4523 - val_acc: 0.5795\n",
            "Epoch 67/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.5690 - acc: 0.7932 - val_loss: 1.4408 - val_acc: 0.5751\n",
            "Epoch 68/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.5530 - acc: 0.7970 - val_loss: 1.4322 - val_acc: 0.5832\n",
            "Epoch 69/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.5528 - acc: 0.7999 - val_loss: 1.4578 - val_acc: 0.5829\n",
            "Epoch 70/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.5347 - acc: 0.8080 - val_loss: 1.4719 - val_acc: 0.5676\n",
            "Epoch 71/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.5215 - acc: 0.8106 - val_loss: 1.5091 - val_acc: 0.5670\n",
            "Epoch 72/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.5323 - acc: 0.8058 - val_loss: 1.4915 - val_acc: 0.5701\n",
            "Epoch 73/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.5139 - acc: 0.8135 - val_loss: 1.4910 - val_acc: 0.5745\n",
            "Epoch 74/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.5185 - acc: 0.8105 - val_loss: 1.5253 - val_acc: 0.5759\n",
            "Epoch 75/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.5214 - acc: 0.8094 - val_loss: 1.4636 - val_acc: 0.5795\n",
            "Epoch 76/200\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.5134 - acc: 0.8147 - val_loss: 1.4954 - val_acc: 0.5698\n",
            "Epoch 77/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.5117 - acc: 0.8141 - val_loss: 1.4484 - val_acc: 0.5798\n",
            "Epoch 78/200\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.5071 - acc: 0.8159 - val_loss: 1.4882 - val_acc: 0.5751\n",
            "Epoch 79/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.5074 - acc: 0.8172 - val_loss: 1.5797 - val_acc: 0.5770\n",
            "Epoch 80/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.4962 - acc: 0.8221 - val_loss: 1.5605 - val_acc: 0.5823\n",
            "Epoch 81/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.4892 - acc: 0.8245 - val_loss: 1.5344 - val_acc: 0.5712\n",
            "Epoch 82/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.4834 - acc: 0.8263 - val_loss: 1.5772 - val_acc: 0.5706\n",
            "Epoch 83/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.4838 - acc: 0.8266 - val_loss: 1.5195 - val_acc: 0.5673\n",
            "Epoch 84/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.4790 - acc: 0.8271 - val_loss: 1.5393 - val_acc: 0.5751\n",
            "Epoch 85/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.4687 - acc: 0.8314 - val_loss: 1.5671 - val_acc: 0.5798\n",
            "Epoch 86/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.4554 - acc: 0.8391 - val_loss: 1.6085 - val_acc: 0.5712\n",
            "Epoch 87/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.4731 - acc: 0.8316 - val_loss: 1.6153 - val_acc: 0.5748\n",
            "Epoch 88/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.4589 - acc: 0.8335 - val_loss: 1.6353 - val_acc: 0.5729\n",
            "Epoch 89/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.4676 - acc: 0.8330 - val_loss: 1.5874 - val_acc: 0.5765\n",
            "Epoch 90/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.4436 - acc: 0.8390 - val_loss: 1.6443 - val_acc: 0.5695\n",
            "Epoch 91/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.4584 - acc: 0.8386 - val_loss: 1.6240 - val_acc: 0.5784\n",
            "Epoch 92/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.4514 - acc: 0.8396 - val_loss: 1.6563 - val_acc: 0.5639\n",
            "Epoch 93/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.4431 - acc: 0.8417 - val_loss: 1.6037 - val_acc: 0.5639\n",
            "Epoch 94/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.4421 - acc: 0.8411 - val_loss: 1.5579 - val_acc: 0.5720\n",
            "Epoch 95/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.4364 - acc: 0.8408 - val_loss: 1.5404 - val_acc: 0.5695\n",
            "Epoch 96/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.4245 - acc: 0.8501 - val_loss: 1.6775 - val_acc: 0.5720\n",
            "Epoch 97/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.4300 - acc: 0.8464 - val_loss: 1.6338 - val_acc: 0.5712\n",
            "Epoch 98/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.4229 - acc: 0.8503 - val_loss: 1.6549 - val_acc: 0.5701\n",
            "Epoch 99/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.4283 - acc: 0.8474 - val_loss: 1.6329 - val_acc: 0.5770\n",
            "Epoch 100/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.4192 - acc: 0.8508 - val_loss: 1.6416 - val_acc: 0.5684\n",
            "Epoch 101/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.4247 - acc: 0.8496 - val_loss: 1.6028 - val_acc: 0.5779\n",
            "Epoch 102/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.4169 - acc: 0.8526 - val_loss: 1.6196 - val_acc: 0.5745\n",
            "Epoch 103/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.4155 - acc: 0.8527 - val_loss: 1.6845 - val_acc: 0.5678\n",
            "Epoch 104/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.4220 - acc: 0.8510 - val_loss: 1.6650 - val_acc: 0.5692\n",
            "Epoch 105/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.4110 - acc: 0.8553 - val_loss: 1.6100 - val_acc: 0.5620\n",
            "Epoch 106/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.4232 - acc: 0.8521 - val_loss: 1.6323 - val_acc: 0.5656\n",
            "Epoch 107/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.4117 - acc: 0.8546 - val_loss: 1.6696 - val_acc: 0.5759\n",
            "Epoch 108/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3984 - acc: 0.8591 - val_loss: 1.7669 - val_acc: 0.5642\n",
            "Epoch 109/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3955 - acc: 0.8600 - val_loss: 1.6740 - val_acc: 0.5782\n",
            "Epoch 110/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.4014 - acc: 0.8593 - val_loss: 1.7157 - val_acc: 0.5709\n",
            "Epoch 111/200\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.3938 - acc: 0.8631 - val_loss: 1.7009 - val_acc: 0.5795\n",
            "Epoch 112/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.4044 - acc: 0.8573 - val_loss: 1.7021 - val_acc: 0.5690\n",
            "Epoch 113/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3923 - acc: 0.8630 - val_loss: 1.7301 - val_acc: 0.5729\n",
            "Epoch 114/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3825 - acc: 0.8681 - val_loss: 1.8037 - val_acc: 0.5639\n",
            "Epoch 115/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3918 - acc: 0.8634 - val_loss: 1.6887 - val_acc: 0.5748\n",
            "Epoch 116/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3813 - acc: 0.8649 - val_loss: 1.8227 - val_acc: 0.5695\n",
            "Epoch 117/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3810 - acc: 0.8667 - val_loss: 1.7369 - val_acc: 0.5720\n",
            "Epoch 118/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3886 - acc: 0.8650 - val_loss: 1.6428 - val_acc: 0.5734\n",
            "Epoch 119/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3735 - acc: 0.8714 - val_loss: 1.7403 - val_acc: 0.5687\n",
            "Epoch 120/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3794 - acc: 0.8678 - val_loss: 1.6621 - val_acc: 0.5748\n",
            "Epoch 121/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3756 - acc: 0.8712 - val_loss: 1.7351 - val_acc: 0.5690\n",
            "Epoch 122/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3713 - acc: 0.8713 - val_loss: 1.7025 - val_acc: 0.5717\n",
            "Epoch 123/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3777 - acc: 0.8684 - val_loss: 1.6702 - val_acc: 0.5662\n",
            "Epoch 124/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3656 - acc: 0.8726 - val_loss: 1.7618 - val_acc: 0.5662\n",
            "Epoch 125/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3736 - acc: 0.8716 - val_loss: 1.7357 - val_acc: 0.5784\n",
            "Epoch 126/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3745 - acc: 0.8709 - val_loss: 1.7745 - val_acc: 0.5631\n",
            "Epoch 127/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3704 - acc: 0.8738 - val_loss: 1.6782 - val_acc: 0.5720\n",
            "Epoch 128/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3681 - acc: 0.8711 - val_loss: 1.7745 - val_acc: 0.5768\n",
            "Epoch 129/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3652 - acc: 0.8764 - val_loss: 1.7043 - val_acc: 0.5698\n",
            "Epoch 130/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3575 - acc: 0.8789 - val_loss: 1.7609 - val_acc: 0.5659\n",
            "Epoch 131/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3628 - acc: 0.8746 - val_loss: 1.7452 - val_acc: 0.5662\n",
            "Epoch 132/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3650 - acc: 0.8739 - val_loss: 1.7913 - val_acc: 0.5653\n",
            "Epoch 133/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3570 - acc: 0.8778 - val_loss: 1.7720 - val_acc: 0.5684\n",
            "Epoch 134/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3539 - acc: 0.8776 - val_loss: 1.8067 - val_acc: 0.5768\n",
            "Epoch 135/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3478 - acc: 0.8788 - val_loss: 1.8158 - val_acc: 0.5656\n",
            "Epoch 136/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3607 - acc: 0.8773 - val_loss: 1.8087 - val_acc: 0.5706\n",
            "Epoch 137/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3531 - acc: 0.8778 - val_loss: 1.8008 - val_acc: 0.5692\n",
            "Epoch 138/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3560 - acc: 0.8782 - val_loss: 1.7446 - val_acc: 0.5793\n",
            "Epoch 139/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3442 - acc: 0.8815 - val_loss: 1.7783 - val_acc: 0.5692\n",
            "Epoch 140/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3486 - acc: 0.8818 - val_loss: 1.8196 - val_acc: 0.5726\n",
            "Epoch 141/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3368 - acc: 0.8845 - val_loss: 1.8001 - val_acc: 0.5706\n",
            "Epoch 142/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3447 - acc: 0.8815 - val_loss: 1.8024 - val_acc: 0.5676\n",
            "Epoch 143/200\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.3390 - acc: 0.8818 - val_loss: 1.7858 - val_acc: 0.5692\n",
            "Epoch 144/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3513 - acc: 0.8807 - val_loss: 1.8013 - val_acc: 0.5776\n",
            "Epoch 145/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3389 - acc: 0.8830 - val_loss: 1.8794 - val_acc: 0.5709\n",
            "Epoch 146/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3366 - acc: 0.8824 - val_loss: 1.8769 - val_acc: 0.5717\n",
            "Epoch 147/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3298 - acc: 0.8852 - val_loss: 1.7870 - val_acc: 0.5748\n",
            "Epoch 148/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3360 - acc: 0.8853 - val_loss: 1.8689 - val_acc: 0.5804\n",
            "Epoch 149/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3256 - acc: 0.8862 - val_loss: 1.8716 - val_acc: 0.5706\n",
            "Epoch 150/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3356 - acc: 0.8855 - val_loss: 1.7906 - val_acc: 0.5773\n",
            "Epoch 151/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3362 - acc: 0.8850 - val_loss: 1.8127 - val_acc: 0.5756\n",
            "Epoch 152/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3231 - acc: 0.8931 - val_loss: 1.8828 - val_acc: 0.5690\n",
            "Epoch 153/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3256 - acc: 0.8898 - val_loss: 1.8626 - val_acc: 0.5648\n",
            "Epoch 154/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3262 - acc: 0.8885 - val_loss: 1.8027 - val_acc: 0.5717\n",
            "Epoch 155/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3296 - acc: 0.8874 - val_loss: 1.9014 - val_acc: 0.5740\n",
            "Epoch 156/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3266 - acc: 0.8879 - val_loss: 1.7987 - val_acc: 0.5653\n",
            "Epoch 157/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3249 - acc: 0.8895 - val_loss: 1.8893 - val_acc: 0.5592\n",
            "Epoch 158/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3270 - acc: 0.8884 - val_loss: 1.7996 - val_acc: 0.5659\n",
            "Epoch 159/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3291 - acc: 0.8897 - val_loss: 1.7796 - val_acc: 0.5667\n",
            "Epoch 160/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3385 - acc: 0.8862 - val_loss: 1.8301 - val_acc: 0.5715\n",
            "Epoch 161/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3316 - acc: 0.8862 - val_loss: 1.8239 - val_acc: 0.5704\n",
            "Epoch 162/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3125 - acc: 0.8938 - val_loss: 1.8945 - val_acc: 0.5561\n",
            "Epoch 163/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3243 - acc: 0.8885 - val_loss: 1.8810 - val_acc: 0.5645\n",
            "Epoch 164/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3150 - acc: 0.8923 - val_loss: 1.8962 - val_acc: 0.5648\n",
            "Epoch 165/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3243 - acc: 0.8905 - val_loss: 1.8643 - val_acc: 0.5687\n",
            "Epoch 166/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3238 - acc: 0.8909 - val_loss: 1.8839 - val_acc: 0.5670\n",
            "Epoch 167/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3221 - acc: 0.8921 - val_loss: 1.9199 - val_acc: 0.5698\n",
            "Epoch 168/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3211 - acc: 0.8922 - val_loss: 1.8677 - val_acc: 0.5712\n",
            "Epoch 169/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3125 - acc: 0.8931 - val_loss: 1.8150 - val_acc: 0.5695\n",
            "Epoch 170/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3018 - acc: 0.8967 - val_loss: 1.8350 - val_acc: 0.5651\n",
            "Epoch 171/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3157 - acc: 0.8938 - val_loss: 1.9005 - val_acc: 0.5776\n",
            "Epoch 172/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3101 - acc: 0.8968 - val_loss: 1.7376 - val_acc: 0.5784\n",
            "Epoch 173/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.2926 - acc: 0.9015 - val_loss: 1.9054 - val_acc: 0.5645\n",
            "Epoch 174/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3104 - acc: 0.8948 - val_loss: 1.8862 - val_acc: 0.5589\n",
            "Epoch 175/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3100 - acc: 0.8945 - val_loss: 1.9087 - val_acc: 0.5793\n",
            "Epoch 176/200\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3101 - acc: 0.8964 - val_loss: 1.8904 - val_acc: 0.5743\n",
            "Epoch 177/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3114 - acc: 0.8952 - val_loss: 1.9100 - val_acc: 0.5687\n",
            "Epoch 178/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3087 - acc: 0.8956 - val_loss: 1.8440 - val_acc: 0.5751\n",
            "Epoch 179/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3186 - acc: 0.8949 - val_loss: 1.8768 - val_acc: 0.5642\n",
            "Epoch 180/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3044 - acc: 0.8986 - val_loss: 1.9380 - val_acc: 0.5662\n",
            "Epoch 181/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.2971 - acc: 0.9001 - val_loss: 1.9293 - val_acc: 0.5698\n",
            "Epoch 182/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3056 - acc: 0.8958 - val_loss: 1.9033 - val_acc: 0.5631\n",
            "Epoch 183/200\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3002 - acc: 0.8966 - val_loss: 1.9461 - val_acc: 0.5748\n",
            "Epoch 184/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3042 - acc: 0.8990 - val_loss: 1.8951 - val_acc: 0.5717\n",
            "Epoch 185/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3005 - acc: 0.8986 - val_loss: 1.9418 - val_acc: 0.5656\n",
            "Epoch 186/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3086 - acc: 0.8991 - val_loss: 1.8882 - val_acc: 0.5659\n",
            "Epoch 187/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3154 - acc: 0.8964 - val_loss: 1.9496 - val_acc: 0.5595\n",
            "Epoch 188/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3068 - acc: 0.8993 - val_loss: 1.9107 - val_acc: 0.5603\n",
            "Epoch 189/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3056 - acc: 0.8986 - val_loss: 1.8563 - val_acc: 0.5681\n",
            "Epoch 190/200\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.2929 - acc: 0.9026 - val_loss: 1.9133 - val_acc: 0.5731\n",
            "Epoch 191/200\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3019 - acc: 0.8995 - val_loss: 1.9807 - val_acc: 0.5673\n",
            "Epoch 192/200\n",
            "17344/28709 [=================>............] - ETA: 3s - loss: 0.2899 - acc: 0.9020"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
